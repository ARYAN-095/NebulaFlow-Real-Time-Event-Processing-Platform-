# NebulaFlow: Real-Time Event Processing Platform  
 
*A scalable platform for ingesting, processing, and visualizing IoT sensor data in real time.*

---

## üöÄ Introduction
IoT Pulse is a cloud-native platform that ingests simulated IoT sensor data (temperature, humidity), processes it in real time, computes live metrics, triggers alerts, and powers a dynamic dashboard. Ideal for smart-building demos, it showcases end-to-end event-driven architecture with enterprise-grade scalability.

---

#  Key Features

  -> Multi‚ÄëTenant Security via JWT + Postgres Row‚ÄëLevel Security

  -> Real‚ÄëTime Streaming: MQTT ‚Üí EMQX ‚Üí Kafka ‚Üí Socket.IO ‚Üí Browser

  -> Durable Storage: Raw sensor_data + 1‚Äëmin/5‚Äëmin aggregates in TimescaleDB

  -> Interactive Dashboard: Next.js frontend with live & historical charts

  -> Device Management: Onboard/decommission devices per tenant

  -> CSV Export: Download raw or aggregated series

  -> Observability: Prometheus metrics, Grafana dashboards, Slack alerts

  -> CI/CD & Containerization: Dockerized services, single docker-compose up


## üåê High-Level Architecture  
```mermaid
graph LR
    A[Edge Simulator] -->|MQTT| B(EMQX Broker)
    B -->|Kafka Connector| C[Apache Kafka]
    C --> D[Stream Processor]
    D --> E[Aggregation Microservice]
    E --> F[TimescaleDB]
    F --> G[API Service]
    G --> H[Dashboard]
    D --> I[Alerting Service]
    I --> J[Prometheus]
    J --> K[Slack/Email]
```


```mermaid
    flowchart LR
  subgraph Edge
    SIM[Node.js Simulator]
  end
  subgraph Cloud
    EMQX[EMQX Broker]
    Kafka[Kafka Cluster]
    ksql[ksqlDB Engine]
    AGG[Aggregation Service]
    TSDB[TimescaleDB]
    API[Express + Socket.IO]
    Graf[Grafana / Alertmanager]
  end
  SIM -->|MQTT| EMQX --> SUB[MQTT‚ÜíKafka Bridge] --> Kafka
  Kafka --> ksql --> TSDB
  Kafka --> AGG --> TSDB
  TSDB --> API --> Dashboard[Next.js App]
  Kafka --> API
  TSDB --> Graf
  AGG --> Graf
```

# üèóÔ∏è Architecture Overview


```mermaid
[Simulator / Real Sensor]
         ‚îÇ MQTT
         ‚ñº
      [EMQX Broker]
         ‚îÇ
         ‚ñº
 [Bridge Service] ‚îÄ‚îÄ‚ñ∂ Apache Kafka ‚îÄ‚îÄ‚ñ∂
         ‚îÇ                              ‚îú‚îÄ [Consumer] ‚Üí TimescaleDB (raw)
         ‚îÇ                              ‚îî‚îÄ [Aggregator] ‚Üí TimescaleDB (aggregates)
         ‚ñº
    [Socket.IO / API]
         ‚îÇ REST & WebSocket
         ‚ñº
  [Next.js Dashboard] ‚Üê‚Üí [DeviceManager UI]
         ‚ñ≤
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ CSV Export
         
[Prometheus] ‚Üê /metrics ‚îÄ [API, Aggregator, Bridge]
[Grafana] visualizes Prometheus & TimescaleDB data
[SlackAlerts] monitors aggregates threshold breaches
```
 
# üì¶ Tech Stack

Layer	                      Technology
Messaging            	MQTT (EMQX), Apache Kafka
Time‚ÄëSeries DB	        TimescaleDB (Postgres)
API & Auth	          Node.js, Express, Socket.IO, JWT, RLS
Aggregation	             Node.js Consumer & KafkaJS
Alerting	               Slack Web API
Frontend              	Next.js, React, SWR, Recharts
Observability       	prom-client, express‚Äëprom-bundle, Prometheus, Grafana
Containerization	        Docker, Docker‚ÄëCompose

# üîß Prerequisites
Docker & Docker‚ÄëCompose

(Locally) Node.js ‚â• 18, npm

(Optional) MQTT tool / real sensors


# ‚öôÔ∏è Quick Start (Docker)

  1. Clone & configure

  ```
  git clone https://github.com/your-org/NebulaFlow.git
  cd NebulaFlow
  cp .env.example .env          # Fill in DB/Kafka/Slack credentials
  ```

  2. Build & spin up all services
   ```
   docker-compose up --build -d

   ```

  3. Initialize Kafka topic (auto‚Äëcreate enabled)

  ```
  # By default, topics will auto‚Äëcreate on broker, otherwise:
  docker exec -it kafka kafka-topics --create \
  --topic iot-sensor-data --bootstrap-server kafka:9092 \
  --partitions 3 --replication-factor 1
  ```

 4. Access services
  
  API: http://localhost:5000

  Dashboard: http://localhost:3000

  EMQX UI: http://localhost:18083 (default guest/guest)

  Prometheus: http://localhost:9090

   Grafana: http://localhost:3000 (anonymous)

 5. Simulate data

```
   # Generate a tenant token:
curl -X POST http://localhost:5000/api/generate-token \
  -H "x-master-key: YOUR_MASTER_KEY" \
  -d '{"tenant_id":"tenant-1"}'
#  ‚ûú { token: "eyJ..." }
export SIM_TOKEN=eyJ...
docker-compose exec simulator node publisher.js --token $SIM_TOKEN
```

6. Log in & visualize

Visit /login in the dashboard, select your tenant, sign in.

Add devices, view real‚Äëtime & aggregated charts, download CSVs.



# üìù Project Structure

```
/
project-root/
‚îú‚îÄ‚îÄ aggregator/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ alert.js
‚îÇ   ‚îú‚îÄ‚îÄ db.js
‚îÇ   ‚îú‚îÄ‚îÄ index.js
‚îÇ   ‚îî‚îÄ‚îÄ utils.js
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ .env
‚îÇ   ‚îú‚îÄ‚îÄ db.js
‚îÇ   ‚îú‚îÄ‚îÄ kafka-consumer.js
‚îÇ   ‚îú‚îÄ‚îÄ server.js
‚îÇ   ‚îî‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ bridge/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ kafka-producer.js
‚îÇ   ‚îî‚îÄ‚îÄ subscriber.js
‚îú‚îÄ‚îÄ consumer/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ kafka-consumer.js
‚îú‚îÄ‚îÄ simulator/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ publisher.js
‚îÇ   ‚îî‚îÄ‚îÄ package.json
‚îú‚îÄ dashboard/       # Next.js React frontend
‚îÇ   ‚îú‚îÄ components/  # LiveChart, DeviceManager, NavBar, LoginPage
‚îÇ   ‚îî‚îÄ pages/‚Ä¶
‚îú‚îÄ docker-compose.yml
|- Dockerfile
‚îú‚îÄ .env             # env vars (DB, Kafka, JWT_SECRET, MASTER_KEY, SLACK_TOKEN,..)
‚îî‚îÄ README.md
```

# üéØ CI/CD & Deployment
GitHub Actions :

Lint & Test on every PR

Build Docker images and push to registry

Helm charts for Kubernetes deployment (EKS/GKE)

Automated Rollouts and Canary Monitoring


# üìä Observability
/metrics exposes Prometheus metrics: HTTP request counts & latencies, process stats

Grafana dashboards visualize end‚Äëto‚Äëend throughput, p95 latencies, consumer lag

Slack alerts for aggregate thresholds via alerter.js

# ü§ù Contributing
Fork & branch (feature/xyz)

Code, test, lint

Open PR against‚ÄØmain

Review, merge, and celebrate! üéâ


# üôã‚Äç‚ôÇÔ∏è Talking Points
Why multi‚Äëtenant? Data isolation + scalability for SaaS IoT platforms

Why Kafka? Durable, replayable event bus decouples producers/consumers

Why TimescaleDB? SQL familiarity + native time‚Äëseries performance

JWT + RLS ensure each tenant only sees their own data

Extensible: swap in real sensors, add more aggregation windows, alerting rules

Next Steps: full GitOps CI/CD, secrets management, production‚Äëgrade Helm charts


# Where Kafka Fits in the Pipeline

```
[Simulator or Real Device]
         ‚îÇ MQTT ‚Üí EMQX
         ‚Üò
   [Bridge Service]
         ‚îÇ PRODUCE ‚Üí Kafka ‚Äúiot-sensor-data‚Äù topic
         ‚îÇ
 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
 ‚îÇ                 ‚îÇ
 ‚ñº                 ‚ñº
Raw Consumer    Aggregator
(writes raw     (computes
 readings to    and writes
  TimescaleDB)  aggregates)
   ‚îÇ                 ‚îÇ
   ‚îî‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îî‚îÄ> API Layer (Socket.IO & REST)  
      serves live & historical charts

```

Bridge (bridge/subscriber.js) takes incoming MQTT messages and publishes them into Kafka.

Raw Consumer (consumer/kafka-consumer.js) subscribes to the same topic and persists each reading in TimescaleDB.

Aggregator (aggregator/index.js) also subscribes, buffers messages for a minute or five, computes averages, and writes those aggregates back to TimescaleDB for efficient querying by the dashboard.

By using Kafka, we ensure each step is loosely coupled, fault-tolerant, and horizontally scalable.



# Putting It All Together

```
[Device/Simulator] 
    ‚Üí (MQTT) 
[EMQX Broker] 
    ‚Üí (bridge) 
[Kafka topic ‚Äúiot-sensor-data‚Äù]
    ‚Üô             ‚Üò
[Raw Consumer]   [Aggregator]
    ‚Üì               ‚Üì
[TimescaleDB raw] [TimescaleDB aggregates]
    ‚Üò               ‚Üô
[Express/Sockets API] ‚Üí [Next.js Dashboard]
```

Every piece has its job:

     EMQX for device-friendly ingestion

     Kafka for rock-solid, replayable streams

     Consumers for storing raw and aggregated data

     API & Dashboard for secure, live visualizations



